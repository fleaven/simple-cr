From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 455.117.The batch test accuracy = 0.0078125 , 0.09375 ，0.25.
After 100 training step(s),loss on training batch is 440.532.The batch test accuracy = 0.0234375 , 0.1875 ，0.296875.
After 200 training step(s),loss on training batch is 425.278.The batch test accuracy = 0.148438 , 0.421875 ，0.625.
After 300 training step(s),loss on training batch is 279.873.The batch test accuracy = 0.335938 , 0.773438 ，0.914062.
After 400 training step(s),loss on training batch is 194.792.The batch test accuracy = 0.523438 , 0.875 ，0.96875.
Interrupted on request...
Train finished...
From /home/fleaven/Documents/AI/ocr/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/fleaven/Documents/AI/ocr/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/fleaven/Documents/AI/ocr/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/fleaven/Documents/AI/ocr/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 115.33.The batch test accuracy = 0 , 0.15625 ，0.34375.
Interrupted on request...
Train finished...
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 449.233.The batch test accuracy = 0.03125 , 0.15625 ，0.28125.
After 100 training step(s),loss on training batch is 450.692.The batch test accuracy = 0.0390625 , 0.210938 ，0.390625.
After 200 training step(s),loss on training batch is 447.227.The batch test accuracy = 0.0546875 , 0.171875 ，0.375.
Interrupted on request...
Train finished...
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 453.768.The batch test accuracy = 0.0546875 , 0.15625 ，0.335938.
After 100 training step(s),loss on training batch is 446.879.The batch test accuracy = 0.046875 , 0.226562 ，0.40625.
After 200 training step(s),loss on training batch is 428.574.The batch test accuracy = 0.0546875 , 0.34375 ，0.640625.
After 300 training step(s),loss on training batch is 287.78.The batch test accuracy = 0.296875 , 0.78125 ，0.875.
Interrupted on request...
Train finished...
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 250.095.The batch test accuracy = 0.4375 , 0.8125 ，0.914062.
After 100 training step(s),loss on training batch is 170.158.The batch test accuracy = 0.664062 , 0.929688 ，0.96875.
After 200 training step(s),loss on training batch is 131.197.The batch test accuracy = 0.625 , 0.90625 ，0.984375.
After 300 training step(s),loss on training batch is 107.402.The batch test accuracy = 0.742188 , 0.96875 ，0.984375.
After 400 training step(s),loss on training batch is 87.0511.The batch test accuracy = 0.742188 , 0.984375 ，1.
After 500 training step(s),loss on training batch is 81.5016.The batch test accuracy = 0.804688 , 1 ，1.
After 600 training step(s),loss on training batch is 65.8525.The batch test accuracy = 0.75 , 0.992188 ，1.
After 700 training step(s),loss on training batch is 62.1566.The batch test accuracy = 0.875 , 0.976562 ，0.992188.
After 800 training step(s),loss on training batch is 33.8982.The batch test accuracy = 0.875 , 0.992188 ，0.992188.
After 900 training step(s),loss on training batch is 41.6819.The batch test accuracy = 0.953125 , 1 ，1.
After 1000 training step(s),loss on training batch is 47.6311.The batch test accuracy = 0.890625 , 1 ，1.
After 1100 training step(s),loss on training batch is 37.3764.The batch test accuracy = 0.875 , 1 ，1.
After 1200 training step(s),loss on training batch is 28.1334.The batch test accuracy = 0.875 , 1 ，1.
After 1300 training step(s),loss on training batch is 29.5781.The batch test accuracy = 0.921875 , 0.984375 ，1.
After 1400 training step(s),loss on training batch is 18.1156.The batch test accuracy = 0.9375 , 1 ，1.
After 1500 training step(s),loss on training batch is 32.8998.The batch test accuracy = 0.90625 , 1 ，1.
After 1600 training step(s),loss on training batch is 12.3951.The batch test accuracy = 0.9375 , 0.992188 ，1.
After 1700 training step(s),loss on training batch is 21.8925.The batch test accuracy = 0.945312 , 1 ，1.
After 1800 training step(s),loss on training batch is 27.1597.The batch test accuracy = 0.960938 , 1 ，1.
After 1900 training step(s),loss on training batch is 8.68886.The batch test accuracy = 0.976562 , 1 ，1.
After 2000 training step(s),loss on training batch is 6.82732.The batch test accuracy = 0.921875 , 1 ，1.
After 2100 training step(s),loss on training batch is 13.5437.The batch test accuracy = 0.984375 , 1 ，1.
After 2200 training step(s),loss on training batch is 9.63824.The batch test accuracy = 0.960938 , 1 ，1.
After 2300 training step(s),loss on training batch is 8.45299.The batch test accuracy = 0.96875 , 1 ，1.
After 2400 training step(s),loss on training batch is 12.6414.The batch test accuracy = 0.945312 , 1 ，1.
After 2500 training step(s),loss on training batch is 5.66007.The batch test accuracy = 1 , 1 ，1.
After 2600 training step(s),loss on training batch is 21.4271.The batch test accuracy = 0.945312 , 1 ，1.
After 2700 training step(s),loss on training batch is 9.86052.The batch test accuracy = 0.976562 , 1 ，1.
After 2800 training step(s),loss on training batch is 9.33257.The batch test accuracy = 0.976562 , 1 ，1.
After 2900 training step(s),loss on training batch is 8.14051.The batch test accuracy = 0.992188 , 1 ，1.
After 3000 training step(s),loss on training batch is 4.23149.The batch test accuracy = 0.960938 , 1 ，1.
After 3100 training step(s),loss on training batch is 8.00238.The batch test accuracy = 0.992188 , 1 ，1.
After 3200 training step(s),loss on training batch is 5.57479.The batch test accuracy = 0.984375 , 1 ，1.
After 3300 training step(s),loss on training batch is 3.56501.The batch test accuracy = 0.976562 , 1 ，1.
After 3400 training step(s),loss on training batch is 15.572.The batch test accuracy = 0.96875 , 1 ，1.
After 3500 training step(s),loss on training batch is 6.69301.The batch test accuracy = 0.960938 , 1 ，1.
After 3600 training step(s),loss on training batch is 3.02691.The batch test accuracy = 0.992188 , 1 ，1.
After 3700 training step(s),loss on training batch is 4.27376.The batch test accuracy = 1 , 1 ，1.
After 3800 training step(s),loss on training batch is 6.2684.The batch test accuracy = 1 , 1 ，1.
After 3900 training step(s),loss on training batch is 2.03474.The batch test accuracy = 0.992188 , 1 ，1.
After 4000 training step(s),loss on training batch is 2.29517.The batch test accuracy = 0.984375 , 1 ，1.
After 4100 training step(s),loss on training batch is 2.32684.The batch test accuracy = 1 , 1 ，1.
After 4200 training step(s),loss on training batch is 2.20665.The batch test accuracy = 1 , 1 ，1.
After 4300 training step(s),loss on training batch is 4.85142.The batch test accuracy = 0.976562 , 1 ，1.
After 4400 training step(s),loss on training batch is 4.76353.The batch test accuracy = 1 , 1 ，1.
After 4500 training step(s),loss on training batch is 2.10095.The batch test accuracy = 1 , 1 ，1.
After 4600 training step(s),loss on training batch is 5.7937.The batch test accuracy = 1 , 1 ，1.
After 4700 training step(s),loss on training batch is 1.06517.The batch test accuracy = 0.976562 , 1 ，1.
After 4800 training step(s),loss on training batch is 4.9909.The batch test accuracy = 1 , 1 ，1.
After 4900 training step(s),loss on training batch is 7.81397.The batch test accuracy = 0.992188 , 1 ，1.
After 5000 training step(s),loss on training batch is 0.808146.The batch test accuracy = 0.992188 , 1 ，1.
After 5100 training step(s),loss on training batch is 2.94926.The batch test accuracy = 0.992188 , 1 ，1.
After 5200 training step(s),loss on training batch is 3.76209.The batch test accuracy = 0.992188 , 1 ，1.
After 5300 training step(s),loss on training batch is 3.41361.The batch test accuracy = 0.984375 , 1 ，1.
After 5400 training step(s),loss on training batch is 3.76702.The batch test accuracy = 0.984375 , 1 ，1.
After 5500 training step(s),loss on training batch is 3.72986.The batch test accuracy = 0.984375 , 1 ，1.
After 5600 training step(s),loss on training batch is 2.29135.The batch test accuracy = 1 , 1 ，1.
After 5700 training step(s),loss on training batch is 4.65589.The batch test accuracy = 0.976562 , 1 ，1.
After 5800 training step(s),loss on training batch is 1.24244.The batch test accuracy = 0.992188 , 1 ，1.
After 5900 training step(s),loss on training batch is 0.317595.The batch test accuracy = 1 , 1 ，1.
After 6000 training step(s),loss on training batch is 1.5799.The batch test accuracy = 0.992188 , 1 ，1.
After 6100 training step(s),loss on training batch is 2.48605.The batch test accuracy = 1 , 1 ，1.
After 6200 training step(s),loss on training batch is 1.52924.The batch test accuracy = 1 , 1 ，1.
After 6300 training step(s),loss on training batch is 1.65736.The batch test accuracy = 0.992188 , 1 ，1.
After 6400 training step(s),loss on training batch is 0.892434.The batch test accuracy = 1 , 1 ，1.
After 6500 training step(s),loss on training batch is 0.130773.The batch test accuracy = 0.984375 , 1 ，1.
After 6600 training step(s),loss on training batch is 0.507948.The batch test accuracy = 0.992188 , 1 ，1.
After 6700 training step(s),loss on training batch is 0.537446.The batch test accuracy = 1 , 1 ，1.
After 6800 training step(s),loss on training batch is 4.18961.The batch test accuracy = 0.992188 , 1 ，1.
After 6900 training step(s),loss on training batch is 1.99922.The batch test accuracy = 1 , 1 ，1.
After 7000 training step(s),loss on training batch is 0.203556.The batch test accuracy = 0.992188 , 1 ，1.
After 7100 training step(s),loss on training batch is 5.08405.The batch test accuracy = 1 , 1 ，1.
After 7200 training step(s),loss on training batch is 0.409448.The batch test accuracy = 0.992188 , 1 ，1.
After 7300 training step(s),loss on training batch is 0.654122.The batch test accuracy = 1 , 1 ，1.
After 7400 training step(s),loss on training batch is 0.843102.The batch test accuracy = 0.992188 , 1 ，1.
After 7500 training step(s),loss on training batch is 0.236428.The batch test accuracy = 1 , 1 ，1.
After 7600 training step(s),loss on training batch is 1.20334.The batch test accuracy = 1 , 1 ，1.
After 7700 training step(s),loss on training batch is 2.70731.The batch test accuracy = 0.992188 , 1 ，1.
After 7800 training step(s),loss on training batch is 1.76691.The batch test accuracy = 1 , 1 ，1.
After 7900 training step(s),loss on training batch is 1.81362.The batch test accuracy = 1 , 1 ，1.
After 8000 training step(s),loss on training batch is 2.15864.The batch test accuracy = 1 , 1 ，1.
After 8100 training step(s),loss on training batch is 5.55216.The batch test accuracy = 1 , 1 ，1.
After 8200 training step(s),loss on training batch is 2.53804.The batch test accuracy = 0.992188 , 1 ，1.
After 8300 training step(s),loss on training batch is 0.393627.The batch test accuracy = 0.984375 , 1 ，1.
After 8400 training step(s),loss on training batch is 0.470575.The batch test accuracy = 1 , 1 ，1.
After 8500 training step(s),loss on training batch is 2.7362.The batch test accuracy = 1 , 1 ，1.
After 8600 training step(s),loss on training batch is 0.622536.The batch test accuracy = 1 , 1 ，1.
After 8700 training step(s),loss on training batch is 0.893358.The batch test accuracy = 0.984375 , 1 ，1.
After 8800 training step(s),loss on training batch is 1.89964.The batch test accuracy = 1 , 1 ，1.
After 8900 training step(s),loss on training batch is 3.98242.The batch test accuracy = 1 , 1 ，1.
After 9000 training step(s),loss on training batch is 3.24451.The batch test accuracy = 0.984375 , 1 ，1.
After 9100 training step(s),loss on training batch is 1.23284.The batch test accuracy = 1 , 1 ，1.
After 9200 training step(s),loss on training batch is 0.441642.The batch test accuracy = 1 , 1 ，1.
After 9300 training step(s),loss on training batch is 1.20696.The batch test accuracy = 1 , 1 ，1.
After 9400 training step(s),loss on training batch is 2.55599.The batch test accuracy = 1 , 1 ，1.
After 9500 training step(s),loss on training batch is 0.942093.The batch test accuracy = 1 , 1 ，1.
After 9600 training step(s),loss on training batch is 0.914438.The batch test accuracy = 0.992188 , 1 ，1.
After 9700 training step(s),loss on training batch is 2.0541.The batch test accuracy = 1 , 1 ，1.
After 9800 training step(s),loss on training batch is 0.266798.The batch test accuracy = 1 , 1 ，1.
After 9900 training step(s),loss on training batch is 4.62874.The batch test accuracy = 1 , 1 ，1.
After 10000 training step(s),loss on training batch is 0.576547.The batch test accuracy = 1 , 1 ，1.
After 10100 training step(s),loss on training batch is 0.203557.The batch test accuracy = 1 , 1 ，1.
After 10200 training step(s),loss on training batch is 1.73318.The batch test accuracy = 1 , 1 ，1.
After 10300 training step(s),loss on training batch is 0.218693.The batch test accuracy = 1 , 1 ，1.
After 10400 training step(s),loss on training batch is 0.258001.The batch test accuracy = 1 , 1 ，1.
After 10500 training step(s),loss on training batch is 0.228116.The batch test accuracy = 1 , 1 ，1.
After 10600 training step(s),loss on training batch is 0.669101.The batch test accuracy = 1 , 1 ，1.
After 10700 training step(s),loss on training batch is 0.590366.The batch test accuracy = 1 , 1 ，1.
After 10800 training step(s),loss on training batch is 0.168819.The batch test accuracy = 0.992188 , 1 ，1.
After 10900 training step(s),loss on training batch is 6.08045.The batch test accuracy = 0.992188 , 1 ，1.
After 11000 training step(s),loss on training batch is 0.619836.The batch test accuracy = 1 , 1 ，1.
After 11100 training step(s),loss on training batch is 0.561439.The batch test accuracy = 1 , 1 ，1.
After 11200 training step(s),loss on training batch is 0.992839.The batch test accuracy = 1 , 1 ，1.
After 11300 training step(s),loss on training batch is 0.241042.The batch test accuracy = 1 , 1 ，1.
After 11400 training step(s),loss on training batch is 0.440907.The batch test accuracy = 1 , 1 ，1.
After 11500 training step(s),loss on training batch is 1.29036.The batch test accuracy = 1 , 1 ，1.
After 11600 training step(s),loss on training batch is 0.822326.The batch test accuracy = 0.992188 , 1 ，1.
After 11700 training step(s),loss on training batch is 0.0731485.The batch test accuracy = 0.992188 , 1 ，1.
After 11800 training step(s),loss on training batch is 0.354758.The batch test accuracy = 1 , 1 ，1.
After 11900 training step(s),loss on training batch is 0.380921.The batch test accuracy = 1 , 1 ，1.
After 12000 training step(s),loss on training batch is 0.56232.The batch test accuracy = 1 , 1 ，1.
After 12100 training step(s),loss on training batch is 0.475402.The batch test accuracy = 1 , 1 ，1.
After 12200 training step(s),loss on training batch is 0.052325.The batch test accuracy = 1 , 1 ，1.
After 12300 training step(s),loss on training batch is 0.203284.The batch test accuracy = 1 , 1 ，1.
After 12400 training step(s),loss on training batch is 0.883202.The batch test accuracy = 0.992188 , 1 ，1.
After 12500 training step(s),loss on training batch is 0.541724.The batch test accuracy = 1 , 1 ，1.
After 12600 training step(s),loss on training batch is 0.497917.The batch test accuracy = 1 , 1 ，1.
After 12700 training step(s),loss on training batch is 0.277121.The batch test accuracy = 0.992188 , 1 ，1.
After 12800 training step(s),loss on training batch is 0.0480141.The batch test accuracy = 1 , 1 ，1.
After 12900 training step(s),loss on training batch is 0.303866.The batch test accuracy = 0.992188 , 1 ，1.
After 13000 training step(s),loss on training batch is 0.208103.The batch test accuracy = 0.992188 , 1 ，1.
After 13100 training step(s),loss on training batch is 0.212065.The batch test accuracy = 1 , 1 ，1.
After 13200 training step(s),loss on training batch is 0.141607.The batch test accuracy = 0.992188 , 1 ，1.
After 13300 training step(s),loss on training batch is 1.20604.The batch test accuracy = 1 , 1 ，1.
After 13400 training step(s),loss on training batch is 0.620713.The batch test accuracy = 1 , 1 ，1.
After 13500 training step(s),loss on training batch is 0.169288.The batch test accuracy = 0.992188 , 1 ，1.
After 13600 training step(s),loss on training batch is 0.0267636.The batch test accuracy = 1 , 1 ，1.
After 13700 training step(s),loss on training batch is 0.972994.The batch test accuracy = 1 , 1 ，1.
After 13800 training step(s),loss on training batch is 2.4326.The batch test accuracy = 1 , 1 ，1.
After 13900 training step(s),loss on training batch is 3.21445.The batch test accuracy = 1 , 1 ，1.
After 14000 training step(s),loss on training batch is 0.0937197.The batch test accuracy = 0.992188 , 1 ，1.
After 14100 training step(s),loss on training batch is 3.44198.The batch test accuracy = 1 , 1 ，1.
After 14200 training step(s),loss on training batch is 0.142238.The batch test accuracy = 1 , 1 ，1.
After 14300 training step(s),loss on training batch is 0.19228.The batch test accuracy = 0.992188 , 1 ，1.
After 14400 training step(s),loss on training batch is 0.445119.The batch test accuracy = 1 , 1 ，1.
After 14500 training step(s),loss on training batch is 0.127574.The batch test accuracy = 0.992188 , 1 ，1.
After 14600 training step(s),loss on training batch is 0.0549236.The batch test accuracy = 0.976562 , 1 ，1.
After 14700 training step(s),loss on training batch is 0.207512.The batch test accuracy = 1 , 1 ，1.
After 14800 training step(s),loss on training batch is 0.245237.The batch test accuracy = 1 , 1 ，1.
After 14900 training step(s),loss on training batch is 1.09504.The batch test accuracy = 1 , 1 ，1.
After 15000 training step(s),loss on training batch is 0.415707.The batch test accuracy = 1 , 1 ，1.
After 15100 training step(s),loss on training batch is 0.104601.The batch test accuracy = 0.984375 , 1 ，1.
After 15200 training step(s),loss on training batch is 0.387162.The batch test accuracy = 0.992188 , 1 ，1.
After 15300 training step(s),loss on training batch is 0.505748.The batch test accuracy = 1 , 1 ，1.
After 15400 training step(s),loss on training batch is 0.113425.The batch test accuracy = 1 , 1 ，1.
After 15500 training step(s),loss on training batch is 0.184705.The batch test accuracy = 1 , 1 ，1.
After 15600 training step(s),loss on training batch is 0.199512.The batch test accuracy = 1 , 1 ，1.
After 15700 training step(s),loss on training batch is 0.0591965.The batch test accuracy = 1 , 1 ，1.
After 15800 training step(s),loss on training batch is 0.896599.The batch test accuracy = 1 , 1 ，1.
After 15900 training step(s),loss on training batch is 0.0349788.The batch test accuracy = 1 , 1 ，1.
After 16000 training step(s),loss on training batch is 0.329947.The batch test accuracy = 1 , 1 ，1.
After 16100 training step(s),loss on training batch is 2.16087.The batch test accuracy = 0.992188 , 1 ，1.
After 16200 training step(s),loss on training batch is 0.0408745.The batch test accuracy = 1 , 1 ，1.
After 16300 training step(s),loss on training batch is 1.21516.The batch test accuracy = 1 , 1 ，1.
After 16400 training step(s),loss on training batch is 0.023019.The batch test accuracy = 0.992188 , 1 ，1.
After 16500 training step(s),loss on training batch is 0.812321.The batch test accuracy = 1 , 1 ，1.
After 16600 training step(s),loss on training batch is 0.132207.The batch test accuracy = 1 , 1 ，1.
After 16700 training step(s),loss on training batch is 0.102391.The batch test accuracy = 1 , 1 ，1.
After 16800 training step(s),loss on training batch is 0.217144.The batch test accuracy = 0.992188 , 1 ，1.
After 16900 training step(s),loss on training batch is 0.0607329.The batch test accuracy = 1 , 1 ，1.
After 17000 training step(s),loss on training batch is 2.66091.The batch test accuracy = 1 , 1 ，1.
After 17100 training step(s),loss on training batch is 0.498216.The batch test accuracy = 1 , 1 ，1.
After 17200 training step(s),loss on training batch is 1.52483.The batch test accuracy = 1 , 1 ，1.
After 17300 training step(s),loss on training batch is 0.00677615.The batch test accuracy = 1 , 1 ，1.
After 17400 training step(s),loss on training batch is 0.0608297.The batch test accuracy = 1 , 1 ，1.
After 17500 training step(s),loss on training batch is 0.574293.The batch test accuracy = 1 , 1 ，1.
After 17600 training step(s),loss on training batch is 0.554013.The batch test accuracy = 1 , 1 ，1.
After 17700 training step(s),loss on training batch is 0.0501114.The batch test accuracy = 1 , 1 ，1.
After 17800 training step(s),loss on training batch is 0.113402.The batch test accuracy = 1 , 1 ，1.
After 17900 training step(s),loss on training batch is 1.76715.The batch test accuracy = 1 , 1 ，1.
After 18000 training step(s),loss on training batch is 0.020768.The batch test accuracy = 1 , 1 ，1.
After 18100 training step(s),loss on training batch is 0.0284026.The batch test accuracy = 1 , 1 ，1.
After 18200 training step(s),loss on training batch is 0.364224.The batch test accuracy = 1 , 1 ，1.
After 18300 training step(s),loss on training batch is 0.0609833.The batch test accuracy = 1 , 1 ，1.
After 18400 training step(s),loss on training batch is 0.093431.The batch test accuracy = 1 , 1 ，1.
After 18500 training step(s),loss on training batch is 0.0491831.The batch test accuracy = 1 , 1 ，1.
After 18600 training step(s),loss on training batch is 0.287971.The batch test accuracy = 1 , 1 ，1.
After 18700 training step(s),loss on training batch is 0.758525.The batch test accuracy = 0.992188 , 1 ，1.
After 18800 training step(s),loss on training batch is 0.111857.The batch test accuracy = 1 , 1 ，1.
After 18900 training step(s),loss on training batch is 2.73786.The batch test accuracy = 1 , 1 ，1.
After 19000 training step(s),loss on training batch is 0.360014.The batch test accuracy = 1 , 1 ，1.
After 19100 training step(s),loss on training batch is 0.169983.The batch test accuracy = 1 , 1 ，1.
After 19200 training step(s),loss on training batch is 0.0303712.The batch test accuracy = 1 , 1 ，1.
After 19300 training step(s),loss on training batch is 1.52927.The batch test accuracy = 1 , 1 ，1.
After 19400 training step(s),loss on training batch is 0.115771.The batch test accuracy = 1 , 1 ，1.
After 19500 training step(s),loss on training batch is 0.141321.The batch test accuracy = 0.992188 , 1 ，1.
After 19600 training step(s),loss on training batch is 0.0488471.The batch test accuracy = 1 , 1 ，1.
After 19700 training step(s),loss on training batch is 0.430539.The batch test accuracy = 1 , 1 ，1.
After 19800 training step(s),loss on training batch is 0.291352.The batch test accuracy = 1 , 1 ，1.
After 19900 training step(s),loss on training batch is 0.0393972.The batch test accuracy = 0.992188 , 1 ，1.
After 20000 training step(s),loss on training batch is 0.0801402.The batch test accuracy = 1 , 1 ，1.
After 20100 training step(s),loss on training batch is 1.28266.The batch test accuracy = 1 , 1 ，1.
After 20200 training step(s),loss on training batch is 0.0481792.The batch test accuracy = 1 , 1 ，1.
After 20300 training step(s),loss on training batch is 0.118989.The batch test accuracy = 1 , 1 ，1.
After 20400 training step(s),loss on training batch is 0.0239009.The batch test accuracy = 1 , 1 ，1.
After 20500 training step(s),loss on training batch is 0.137853.The batch test accuracy = 1 , 1 ，1.
After 20600 training step(s),loss on training batch is 0.03288.The batch test accuracy = 1 , 1 ，1.
After 20700 training step(s),loss on training batch is 0.0894578.The batch test accuracy = 1 , 1 ，1.
After 20800 training step(s),loss on training batch is 0.134468.The batch test accuracy = 1 , 1 ，1.
After 20900 training step(s),loss on training batch is 0.0236034.The batch test accuracy = 0.992188 , 1 ，1.
After 21000 training step(s),loss on training batch is 0.274735.The batch test accuracy = 1 , 1 ，1.
After 21100 training step(s),loss on training batch is 0.193129.The batch test accuracy = 1 , 1 ，1.
After 21200 training step(s),loss on training batch is 10.4183.The batch test accuracy = 0.992188 , 1 ，1.
After 21300 training step(s),loss on training batch is 0.351495.The batch test accuracy = 1 , 1 ，1.
After 21400 training step(s),loss on training batch is 1.839.The batch test accuracy = 1 , 1 ，1.
After 21500 training step(s),loss on training batch is 0.303897.The batch test accuracy = 0.992188 , 1 ，1.
After 21600 training step(s),loss on training batch is 0.233747.The batch test accuracy = 1 , 1 ，1.
After 21700 training step(s),loss on training batch is 1.13633.The batch test accuracy = 1 , 1 ，1.
After 21800 training step(s),loss on training batch is 0.32158.The batch test accuracy = 1 , 1 ，1.
After 21900 training step(s),loss on training batch is 0.922402.The batch test accuracy = 0.992188 , 1 ，1.
After 22000 training step(s),loss on training batch is 0.0210428.The batch test accuracy = 1 , 1 ，1.
After 22100 training step(s),loss on training batch is 1.53493.The batch test accuracy = 1 , 1 ，1.
After 22200 training step(s),loss on training batch is 0.0396953.The batch test accuracy = 1 , 1 ，1.
After 22300 training step(s),loss on training batch is 0.0172194.The batch test accuracy = 1 , 1 ，1.
After 22400 training step(s),loss on training batch is 0.41904.The batch test accuracy = 1 , 1 ，1.
After 22500 training step(s),loss on training batch is 0.0570404.The batch test accuracy = 1 , 1 ，1.
After 22600 training step(s),loss on training batch is 0.0121891.The batch test accuracy = 1 , 1 ，1.
After 22700 training step(s),loss on training batch is 0.362667.The batch test accuracy = 1 , 1 ，1.
After 22800 training step(s),loss on training batch is 0.0511571.The batch test accuracy = 1 , 1 ，1.
After 22900 training step(s),loss on training batch is 0.017986.The batch test accuracy = 1 , 1 ，1.
After 23000 training step(s),loss on training batch is 0.535678.The batch test accuracy = 1 , 1 ，1.
After 23100 training step(s),loss on training batch is 0.0323718.The batch test accuracy = 1 , 1 ，1.
After 23200 training step(s),loss on training batch is 1.73368.The batch test accuracy = 1 , 1 ，1.
After 23300 training step(s),loss on training batch is 0.0839857.The batch test accuracy = 1 , 1 ，1.
After 23400 training step(s),loss on training batch is 0.169864.The batch test accuracy = 0.992188 , 1 ，1.
After 23500 training step(s),loss on training batch is 0.925364.The batch test accuracy = 1 , 1 ，1.
After 23600 training step(s),loss on training batch is 0.185018.The batch test accuracy = 1 , 1 ，1.
After 23700 training step(s),loss on training batch is 0.0202874.The batch test accuracy = 1 , 1 ，1.
After 23800 training step(s),loss on training batch is 0.0493519.The batch test accuracy = 1 , 1 ，1.
After 23900 training step(s),loss on training batch is 0.0532559.The batch test accuracy = 1 , 1 ，1.
After 24000 training step(s),loss on training batch is 0.021083.The batch test accuracy = 1 , 1 ，1.
After 24100 training step(s),loss on training batch is 0.0790979.The batch test accuracy = 1 , 1 ，1.
After 24200 training step(s),loss on training batch is 0.30216.The batch test accuracy = 1 , 1 ，1.
After 24300 training step(s),loss on training batch is 0.00436196.The batch test accuracy = 0.992188 , 1 ，1.
After 24400 training step(s),loss on training batch is 0.155445.The batch test accuracy = 1 , 1 ，1.
After 24500 training step(s),loss on training batch is 0.220527.The batch test accuracy = 1 , 1 ，1.
After 24600 training step(s),loss on training batch is 0.618071.The batch test accuracy = 1 , 1 ，1.
After 24700 training step(s),loss on training batch is 0.0568576.The batch test accuracy = 1 , 1 ，1.
After 24800 training step(s),loss on training batch is 0.0253097.The batch test accuracy = 1 , 1 ，1.
After 24900 training step(s),loss on training batch is 0.11683.The batch test accuracy = 0.992188 , 1 ，1.
After 25000 training step(s),loss on training batch is 1.46687.The batch test accuracy = 1 , 1 ，1.
After 25100 training step(s),loss on training batch is 0.00750577.The batch test accuracy = 1 , 1 ，1.
After 25200 training step(s),loss on training batch is 0.0175804.The batch test accuracy = 1 , 1 ，1.
After 25300 training step(s),loss on training batch is 0.140729.The batch test accuracy = 0.992188 , 1 ，1.
After 25400 training step(s),loss on training batch is 1.38643.The batch test accuracy = 0.992188 , 1 ，1.
After 25500 training step(s),loss on training batch is 0.00364945.The batch test accuracy = 1 , 1 ，1.
After 25600 training step(s),loss on training batch is 0.0738814.The batch test accuracy = 1 , 1 ，1.
After 25700 training step(s),loss on training batch is 0.0753753.The batch test accuracy = 0.992188 , 1 ，1.
After 25800 training step(s),loss on training batch is 0.0040189.The batch test accuracy = 1 , 1 ，1.
After 25900 training step(s),loss on training batch is 0.109702.The batch test accuracy = 1 , 1 ，1.
After 26000 training step(s),loss on training batch is 0.0196907.The batch test accuracy = 1 , 1 ，1.
After 26100 training step(s),loss on training batch is 0.05135.The batch test accuracy = 1 , 1 ，1.
After 26200 training step(s),loss on training batch is 0.733539.The batch test accuracy = 1 , 1 ，1.
After 26300 training step(s),loss on training batch is 0.137651.The batch test accuracy = 0.992188 , 1 ，1.
After 26400 training step(s),loss on training batch is 0.291908.The batch test accuracy = 1 , 1 ，1.
After 26500 training step(s),loss on training batch is 0.067528.The batch test accuracy = 1 , 1 ，1.
After 26600 training step(s),loss on training batch is 0.00728315.The batch test accuracy = 1 , 1 ，1.
After 26700 training step(s),loss on training batch is 0.668976.The batch test accuracy = 1 , 1 ，1.
After 26800 training step(s),loss on training batch is 0.0438924.The batch test accuracy = 1 , 1 ，1.
After 26900 training step(s),loss on training batch is 0.121691.The batch test accuracy = 1 , 1 ，1.
After 27000 training step(s),loss on training batch is 0.0826373.The batch test accuracy = 1 , 1 ，1.
After 27100 training step(s),loss on training batch is 0.248263.The batch test accuracy = 1 , 1 ，1.
After 27200 training step(s),loss on training batch is 0.0325326.The batch test accuracy = 1 , 1 ，1.
After 27300 training step(s),loss on training batch is 0.032337.The batch test accuracy = 1 , 1 ，1.
After 27400 training step(s),loss on training batch is 0.00296135.The batch test accuracy = 1 , 1 ，1.
After 27500 training step(s),loss on training batch is 0.501355.The batch test accuracy = 1 , 1 ，1.
After 27600 training step(s),loss on training batch is 0.100718.The batch test accuracy = 0.992188 , 1 ，1.
After 27700 training step(s),loss on training batch is 0.0294583.The batch test accuracy = 1 , 1 ，1.
After 27800 training step(s),loss on training batch is 0.19998.The batch test accuracy = 1 , 1 ，1.
After 27900 training step(s),loss on training batch is 0.121202.The batch test accuracy = 1 , 1 ，1.
After 28000 training step(s),loss on training batch is 0.87451.The batch test accuracy = 1 , 1 ，1.
After 28100 training step(s),loss on training batch is 3.78504.The batch test accuracy = 1 , 1 ，1.
After 28200 training step(s),loss on training batch is 0.046153.The batch test accuracy = 0.992188 , 1 ，1.
After 28300 training step(s),loss on training batch is 0.130936.The batch test accuracy = 1 , 1 ，1.
After 28400 training step(s),loss on training batch is 0.532583.The batch test accuracy = 1 , 1 ，1.
After 28500 training step(s),loss on training batch is 3.54527.The batch test accuracy = 1 , 1 ，1.
After 28600 training step(s),loss on training batch is 0.00755445.The batch test accuracy = 1 , 1 ，1.
After 28700 training step(s),loss on training batch is 0.0542129.The batch test accuracy = 1 , 1 ，1.
After 28800 training step(s),loss on training batch is 1.52049.The batch test accuracy = 0.992188 , 1 ，1.
After 28900 training step(s),loss on training batch is 0.647274.The batch test accuracy = 1 , 1 ，1.
After 29000 training step(s),loss on training batch is 0.0127163.The batch test accuracy = 0.992188 , 1 ，1.
After 29100 training step(s),loss on training batch is 0.370106.The batch test accuracy = 1 , 1 ，1.
After 29200 training step(s),loss on training batch is 0.00588395.The batch test accuracy = 1 , 1 ，1.
After 29300 training step(s),loss on training batch is 0.0479291.The batch test accuracy = 1 , 1 ，1.
After 29400 training step(s),loss on training batch is 0.0191925.The batch test accuracy = 1 , 1 ，1.
After 29500 training step(s),loss on training batch is 0.317302.The batch test accuracy = 1 , 1 ，1.
After 29600 training step(s),loss on training batch is 0.968338.The batch test accuracy = 1 , 1 ，1.
After 29700 training step(s),loss on training batch is 0.0965405.The batch test accuracy = 1 , 1 ，1.
After 29800 training step(s),loss on training batch is 1.12649.The batch test accuracy = 1 , 1 ，1.
After 29900 training step(s),loss on training batch is 0.00925448.The batch test accuracy = 1 , 1 ，1.
Train finished...
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 0.0808492.The batch test accuracy = 1 , 1 ，1.
After 100 training step(s),loss on training batch is 0.110907.The batch test accuracy = 1 , 1 ，1.
After 200 training step(s),loss on training batch is 0.00254443.The batch test accuracy = 1 , 1 ，1.
After 300 training step(s),loss on training batch is 0.687973.The batch test accuracy = 1 , 1 ，1.
After 400 training step(s),loss on training batch is 0.0127948.The batch test accuracy = 1 , 1 ，1.
After 500 training step(s),loss on training batch is 0.0628824.The batch test accuracy = 1 , 1 ，1.
After 600 training step(s),loss on training batch is 0.0190584.The batch test accuracy = 1 , 1 ，1.
After 700 training step(s),loss on training batch is 0.061876.The batch test accuracy = 1 , 1 ，1.
After 800 training step(s),loss on training batch is 0.0334739.The batch test accuracy = 1 , 1 ，1.
After 900 training step(s),loss on training batch is 0.023234.The batch test accuracy = 1 , 1 ，1.
After 1000 training step(s),loss on training batch is 0.13912.The batch test accuracy = 1 , 1 ，1.
After 1100 training step(s),loss on training batch is 0.0298743.The batch test accuracy = 1 , 1 ，1.
After 1200 training step(s),loss on training batch is 0.0381326.The batch test accuracy = 1 , 1 ，1.
After 1300 training step(s),loss on training batch is 0.0174331.The batch test accuracy = 1 , 1 ，1.
After 1400 training step(s),loss on training batch is 0.00662805.The batch test accuracy = 1 , 1 ，1.
After 1500 training step(s),loss on training batch is 1.30631.The batch test accuracy = 1 , 1 ，1.
After 1600 training step(s),loss on training batch is 1.62615.The batch test accuracy = 1 , 1 ，1.
After 1700 training step(s),loss on training batch is 0.0565546.The batch test accuracy = 1 , 1 ，1.
After 1800 training step(s),loss on training batch is 0.0505533.The batch test accuracy = 1 , 1 ，1.
After 1900 training step(s),loss on training batch is 0.0128088.The batch test accuracy = 0.992188 , 1 ，1.
After 2000 training step(s),loss on training batch is 0.0519652.The batch test accuracy = 1 , 1 ，1.
After 2100 training step(s),loss on training batch is 0.00304177.The batch test accuracy = 1 , 1 ，1.
After 2200 training step(s),loss on training batch is 0.157328.The batch test accuracy = 1 , 1 ，1.
After 2300 training step(s),loss on training batch is 1.12471.The batch test accuracy = 1 , 1 ，1.
After 2400 training step(s),loss on training batch is 0.0242828.The batch test accuracy = 1 , 1 ，1.
After 2500 training step(s),loss on training batch is 0.0611112.The batch test accuracy = 1 , 1 ，1.
After 2600 training step(s),loss on training batch is 0.00984485.The batch test accuracy = 1 , 1 ，1.
After 2700 training step(s),loss on training batch is 0.104567.The batch test accuracy = 1 , 1 ，1.
After 2800 training step(s),loss on training batch is 0.0104494.The batch test accuracy = 1 , 1 ，1.
Interrupted on request...
Train finished...
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train.py:93: The name tf.log is deprecated. Please use tf.math.log instead.

From /home/archlab/AI/simple-cr/train.py:95: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

From /home/archlab/AI/simple-cr/train.py:97: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/AI/simple-cr/train.py:100: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

From /home/archlab/AI/simple-cr/train.py:107: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train.py:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 0 training step(s),loss on training batch is 0.0512711.The batch test accuracy = 1 , 1 ，1.
After 100 training step(s),loss on training batch is 0.00782749.The batch test accuracy = 1 , 1 ，1.
After 200 training step(s),loss on training batch is 0.0585384.The batch test accuracy = 1 , 1 ，1.
After 300 training step(s),loss on training batch is 0.071932.The batch test accuracy = 1 , 1 ，1.
After 400 training step(s),loss on training batch is 0.186228.The batch test accuracy = 1 , 1 ，1.
After 500 training step(s),loss on training batch is 0.00245712.The batch test accuracy = 1 , 1 ，1.
After 600 training step(s),loss on training batch is 0.019372.The batch test accuracy = 1 , 1 ，1.
After 700 training step(s),loss on training batch is 0.0504648.The batch test accuracy = 1 , 1 ，1.
After 800 training step(s),loss on training batch is 0.0558083.The batch test accuracy = 1 , 1 ，1.
After 900 training step(s),loss on training batch is 0.00789081.The batch test accuracy = 1 , 1 ，1.
After 1000 training step(s),loss on training batch is 0.0755054.The batch test accuracy = 1 , 1 ，1.
After 1100 training step(s),loss on training batch is 0.0481434.The batch test accuracy = 1 , 1 ，1.
After 1200 training step(s),loss on training batch is 0.0320326.The batch test accuracy = 1 , 1 ，1.
After 1300 training step(s),loss on training batch is 0.023537.The batch test accuracy = 1 , 1 ，1.
After 1400 training step(s),loss on training batch is 0.0663653.The batch test accuracy = 1 , 1 ，1.
After 1500 training step(s),loss on training batch is 0.0261788.The batch test accuracy = 1 , 1 ，1.
After 1600 training step(s),loss on training batch is 0.0124532.The batch test accuracy = 1 , 1 ，1.
After 1700 training step(s),loss on training batch is 0.00992659.The batch test accuracy = 1 , 1 ，1.
After 1800 training step(s),loss on training batch is 0.118026.The batch test accuracy = 1 , 1 ，1.
After 1900 training step(s),loss on training batch is 3.21492.The batch test accuracy = 1 , 1 ，1.
After 2000 training step(s),loss on training batch is 0.198493.The batch test accuracy = 1 , 1 ，1.
After 2100 training step(s),loss on training batch is 0.00371633.The batch test accuracy = 1 , 1 ，1.
After 2200 training step(s),loss on training batch is 0.226146.The batch test accuracy = 1 , 1 ，1.
After 2300 training step(s),loss on training batch is 0.212447.The batch test accuracy = 1 , 1 ，1.
After 2400 training step(s),loss on training batch is 0.796817.The batch test accuracy = 1 , 1 ，1.
After 2500 training step(s),loss on training batch is 0.53434.The batch test accuracy = 1 , 1 ，1.
After 2600 training step(s),loss on training batch is 0.255471.The batch test accuracy = 1 , 1 ，1.
After 2700 training step(s),loss on training batch is 0.00591711.The batch test accuracy = 1 , 1 ，1.
After 2800 training step(s),loss on training batch is 0.294296.The batch test accuracy = 1 , 1 ，1.
After 2900 training step(s),loss on training batch is 0.00797668.The batch test accuracy = 0.992188 , 1 ，1.
After 3000 training step(s),loss on training batch is 0.000559947.The batch test accuracy = 1 , 1 ，1.
After 3100 training step(s),loss on training batch is 0.0802607.The batch test accuracy = 1 , 1 ，1.
After 3200 training step(s),loss on training batch is 0.00146638.The batch test accuracy = 1 , 1 ，1.
After 3300 training step(s),loss on training batch is 0.0333445.The batch test accuracy = 1 , 1 ，1.
After 3400 training step(s),loss on training batch is 0.396326.The batch test accuracy = 1 , 1 ，1.
After 3500 training step(s),loss on training batch is 0.0442818.The batch test accuracy = 1 , 1 ，1.
After 3600 training step(s),loss on training batch is 0.724145.The batch test accuracy = 1 , 1 ，1.
After 3700 training step(s),loss on training batch is 1.55725.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

After 3800 training step(s),loss on training batch is 0.00148659.The batch test accuracy = 1 , 1 ，1.
After 3900 training step(s),loss on training batch is 0.0381788.The batch test accuracy = 1 , 1 ，1.
After 4000 training step(s),loss on training batch is 0.0531055.The batch test accuracy = 1 , 1 ，1.
After 4100 training step(s),loss on training batch is 0.0381233.The batch test accuracy = 1 , 1 ，1.
After 4200 training step(s),loss on training batch is 9.58958.The batch test accuracy = 1 , 1 ，1.
After 4300 training step(s),loss on training batch is 0.118638.The batch test accuracy = 1 , 1 ，1.
After 4400 training step(s),loss on training batch is 0.00274773.The batch test accuracy = 1 , 1 ，1.
After 4500 training step(s),loss on training batch is 0.18765.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train_hccr.py:114: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 4600 training step(s),loss on training batch is 0.0160532.The batch test accuracy = 1 , 1 ，1.
After 4700 training step(s),loss on training batch is 0.00158228.The batch test accuracy = 0.992188 , 1 ，1.
After 4800 training step(s),loss on training batch is 0.0791955.The batch test accuracy = 1 , 1 ，1.
After 4900 training step(s),loss on training batch is 0.19438.The batch test accuracy = 1 , 1 ，1.
After 5000 training step(s),loss on training batch is 0.0412598.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

After 5100 training step(s),loss on training batch is 0.0625728.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Restoring parameters from ./checkpoint_x3/trainnum_30000_-0
Resume training ... Start from step 0 / 30000 .
From /home/archlab/AI/simple-cr/train_hccr.py:114: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 5200 training step(s),loss on training batch is 0.00771489.The batch test accuracy = 1 , 1 ，1.
After 5300 training step(s),loss on training batch is 0.062305.The batch test accuracy = 1 , 1 ，1.
After 5400 training step(s),loss on training batch is 0.0161092.The batch test accuracy = 1 , 1 ，1.
After 5500 training step(s),loss on training batch is 0.0263278.The batch test accuracy = 1 , 1 ，1.
After 5600 training step(s),loss on training batch is 0.0406752.The batch test accuracy = 1 , 1 ，1.
After 5700 training step(s),loss on training batch is 0.356764.The batch test accuracy = 1 , 1 ，1.
After 5800 training step(s),loss on training batch is 0.107319.The batch test accuracy = 1 , 1 ，1.
After 5900 training step(s),loss on training batch is 0.0184888.The batch test accuracy = 1 , 1 ，1.
After 6000 training step(s),loss on training batch is 3.22957.The batch test accuracy = 1 , 1 ，1.
After 6100 training step(s),loss on training batch is 0.168818.The batch test accuracy = 0.992188 , 1 ，1.
After 6200 training step(s),loss on training batch is 1.22017.The batch test accuracy = 1 , 1 ，1.
After 6300 training step(s),loss on training batch is 0.0656177.The batch test accuracy = 1 , 1 ，1.
After 6400 training step(s),loss on training batch is 0.00503981.The batch test accuracy = 1 , 1 ，1.
After 6500 training step(s),loss on training batch is 0.35416.The batch test accuracy = 1 , 1 ，1.
After 6600 training step(s),loss on training batch is 0.0852827.The batch test accuracy = 1 , 1 ，1.
After 6700 training step(s),loss on training batch is 0.00736159.The batch test accuracy = 1 , 1 ，1.
After 6800 training step(s),loss on training batch is 0.519141.The batch test accuracy = 1 , 1 ，1.
After 6900 training step(s),loss on training batch is 0.00865922.The batch test accuracy = 1 , 1 ，1.
After 7000 training step(s),loss on training batch is 0.0279057.The batch test accuracy = 1 , 1 ，1.
After 7100 training step(s),loss on training batch is 0.0770225.The batch test accuracy = 0.992188 , 1 ，1.
After 7200 training step(s),loss on training batch is 0.151548.The batch test accuracy = 1 , 1 ，1.
After 7300 training step(s),loss on training batch is 0.0126013.The batch test accuracy = 1 , 1 ，1.
After 7400 training step(s),loss on training batch is 0.0518717.The batch test accuracy = 1 , 1 ，1.
After 7500 training step(s),loss on training batch is 0.00396161.The batch test accuracy = 1 , 1 ，1.
After 7600 training step(s),loss on training batch is 0.0302146.The batch test accuracy = 1 , 1 ，1.
After 7700 training step(s),loss on training batch is 0.011005.The batch test accuracy = 1 , 1 ，1.
After 7800 training step(s),loss on training batch is 0.112821.The batch test accuracy = 1 , 1 ，1.
After 7900 training step(s),loss on training batch is 0.0187904.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
After 8000 training step(s),loss on training batch is 0.0207764.The batch test accuracy = 1 , 1 ，1.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train_hccr.py:114: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 8100 training step(s),loss on training batch is 0.00106144.The batch test accuracy = 1 , 1 ，1.
After 8200 training step(s),loss on training batch is 0.0550587.The batch test accuracy = 1 , 1 ，1.
After 8300 training step(s),loss on training batch is 0.0026681.The batch test accuracy = 1 , 1 ，1.
After 8400 training step(s),loss on training batch is 0.117707.The batch test accuracy = 1 , 1 ，1.
After 8500 training step(s),loss on training batch is 0.0334553.The batch test accuracy = 1 , 1 ，1.
After 8600 training step(s),loss on training batch is 0.346927.The batch test accuracy = 1 , 1 ，1.
After 8700 training step(s),loss on training batch is 0.0395651.The batch test accuracy = 1 , 1 ，1.
After 8800 training step(s),loss on training batch is 0.0910472.The batch test accuracy = 1 , 1 ，1.
After 8900 training step(s),loss on training batch is 0.163861.The batch test accuracy = 1 , 1 ，1.
After 9000 training step(s),loss on training batch is 0.00133355.The batch test accuracy = 1 , 1 ，1.
After 9100 training step(s),loss on training batch is 0.032529.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train_hccr.py:114: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 9200 training step(s),loss on training batch is 0.00312502.The batch test accuracy = 1 , 1 ，1.
After 9300 training step(s),loss on training batch is 0.644943.The batch test accuracy = 1 , 1 ，1.
After 9400 training step(s),loss on training batch is 0.307321.The batch test accuracy = 1 , 1 ，1.
After 9500 training step(s),loss on training batch is 0.473204.The batch test accuracy = 0.992188 , 1 ，1.
After 9600 training step(s),loss on training batch is 0.00566025.The batch test accuracy = 1 , 1 ，1.
After 9700 training step(s),loss on training batch is 0.00168085.The batch test accuracy = 1 , 1 ，1.
After 9800 training step(s),loss on training batch is 0.0201267.The batch test accuracy = 1 , 1 ，1.
After 9900 training step(s),loss on training batch is 0.0222444.The batch test accuracy = 1 , 1 ，1.
After 10000 training step(s),loss on training batch is 0.0136213.The batch test accuracy = 1 , 1 ，1.
From /home/archlab/AI/simple-cr/data.py:58: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.

The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:53: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
From /home/archlab/AI/simple-cr/models/basiccnn3.py:115: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

From /home/archlab/AI/simple-cr/models/basiccnn3.py:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

From /home/archlab/AI/simple-cr/train_hccr.py:75: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

From /home/archlab/AI/simple-cr/train_hccr.py:78: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

From /home/archlab/miniconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
From /home/archlab/AI/simple-cr/train_hccr.py:86: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

From /home/archlab/AI/simple-cr/train_hccr.py:87: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

From /home/archlab/AI/simple-cr/train_hccr.py:95: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

From /home/archlab/AI/simple-cr/train_hccr.py:99: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

From /home/archlab/AI/simple-cr/train_hccr.py:114: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.
After 10100 training step(s),loss on training batch is 0.697186.The batch test accuracy = 1 , 1 ，1.
After 10200 training step(s),loss on training batch is 0.0937402.The batch test accuracy = 1 , 1 ，1.
After 10300 training step(s),loss on training batch is 0.00610557.The batch test accuracy = 1 , 1 ，1.
After 10400 training step(s),loss on training batch is 0.144155.The batch test accuracy = 1 , 1 ，1.
After 10500 training step(s),loss on training batch is 0.0348872.The batch test accuracy = 0.992188 , 1 ，1.
After 10600 training step(s),loss on training batch is 0.0639354.The batch test accuracy = 1 , 1 ，1.
After 10700 training step(s),loss on training batch is 0.0199925.The batch test accuracy = 1 , 1 ，1.
After 10800 training step(s),loss on training batch is 0.108684.The batch test accuracy = 1 , 1 ，1.
After 10900 training step(s),loss on training batch is 0.00416478.The batch test accuracy = 1 , 1 ，1.
After 11000 training step(s),loss on training batch is 0.00384256.The batch test accuracy = 1 , 1 ，1.
After 11100 training step(s),loss on training batch is 0.00485947.The batch test accuracy = 1 , 1 ，1.
After 11200 training step(s),loss on training batch is 0.0154309.The batch test accuracy = 1 , 1 ，1.
After 11300 training step(s),loss on training batch is 0.0133217.The batch test accuracy = 1 , 1 ，1.
After 11400 training step(s),loss on training batch is 0.0578373.The batch test accuracy = 1 , 1 ，1.
After 11500 training step(s),loss on training batch is 0.00321928.The batch test accuracy = 1 , 1 ，1.
After 11600 training step(s),loss on training batch is 0.0130524.The batch test accuracy = 1 , 1 ，1.
After 11700 training step(s),loss on training batch is 0.013515.The batch test accuracy = 1 , 1 ，1.
After 11800 training step(s),loss on training batch is 1.73614.The batch test accuracy = 1 , 1 ，1.
After 11900 training step(s),loss on training batch is 0.0122058.The batch test accuracy = 1 , 1 ，1.
After 12000 training step(s),loss on training batch is 0.0454845.The batch test accuracy = 1 , 1 ，1.
After 12100 training step(s),loss on training batch is 0.0109014.The batch test accuracy = 1 , 1 ，1.
After 12200 training step(s),loss on training batch is 0.00744618.The batch test accuracy = 1 , 1 ，1.
After 12300 training step(s),loss on training batch is 0.013613.The batch test accuracy = 0.992188 , 1 ，1.
After 12400 training step(s),loss on training batch is 0.0492637.The batch test accuracy = 0.992188 , 1 ，1.
After 12500 training step(s),loss on training batch is 0.00370379.The batch test accuracy = 1 , 1 ，1.
After 12600 training step(s),loss on training batch is 0.0237489.The batch test accuracy = 0.992188 , 1 ，1.
After 12700 training step(s),loss on training batch is 0.206338.The batch test accuracy = 1 , 1 ，1.
After 12800 training step(s),loss on training batch is 0.0224597.The batch test accuracy = 1 , 1 ，1.
After 12900 training step(s),loss on training batch is 0.0236299.The batch test accuracy = 1 , 1 ，1.
After 13000 training step(s),loss on training batch is 0.00384373.The batch test accuracy = 1 , 1 ，1.
After 13100 training step(s),loss on training batch is 0.0107366.The batch test accuracy = 1 , 1 ，1.
After 13200 training step(s),loss on training batch is 0.0114276.The batch test accuracy = 1 , 1 ，1.
After 13300 training step(s),loss on training batch is 1.92676.The batch test accuracy = 1 , 1 ，1.
After 13400 training step(s),loss on training batch is 0.004979.The batch test accuracy = 1 , 1 ，1.
After 13500 training step(s),loss on training batch is 0.00559326.The batch test accuracy = 1 , 1 ，1.
After 13600 training step(s),loss on training batch is 0.0157889.The batch test accuracy = 1 , 1 ，1.
After 13700 training step(s),loss on training batch is 0.0306145.The batch test accuracy = 1 , 1 ，1.
After 13800 training step(s),loss on training batch is 0.00686632.The batch test accuracy = 1 , 1 ，1.
After 13900 training step(s),loss on training batch is 0.157023.The batch test accuracy = 1 , 1 ，1.
After 14000 training step(s),loss on training batch is 0.0323044.The batch test accuracy = 1 , 1 ，1.
After 14100 training step(s),loss on training batch is 0.18848.The batch test accuracy = 1 , 1 ，1.
After 14200 training step(s),loss on training batch is 0.0362282.The batch test accuracy = 1 , 1 ，1.
After 14300 training step(s),loss on training batch is 0.00527634.The batch test accuracy = 1 , 1 ，1.
After 14400 training step(s),loss on training batch is 0.0175871.The batch test accuracy = 1 , 1 ，1.
After 14500 training step(s),loss on training batch is 0.165594.The batch test accuracy = 1 , 1 ，1.
After 14600 training step(s),loss on training batch is 0.00595058.The batch test accuracy = 1 , 1 ，1.
After 14700 training step(s),loss on training batch is 0.000136974.The batch test accuracy = 1 , 1 ，1.
After 14800 training step(s),loss on training batch is 0.0413576.The batch test accuracy = 1 , 1 ，1.
After 14900 training step(s),loss on training batch is 0.00194934.The batch test accuracy = 1 , 1 ，1.
After 15000 training step(s),loss on training batch is 0.0111943.The batch test accuracy = 1 , 1 ，1.
After 15100 training step(s),loss on training batch is 0.00936194.The batch test accuracy = 0.992188 , 1 ，1.
After 15200 training step(s),loss on training batch is 0.00320726.The batch test accuracy = 1 , 1 ，1.
After 15300 training step(s),loss on training batch is 0.254941.The batch test accuracy = 1 , 1 ，1.
After 15400 training step(s),loss on training batch is 0.0138152.The batch test accuracy = 1 , 1 ，1.
After 15500 training step(s),loss on training batch is 0.113396.The batch test accuracy = 1 , 1 ，1.
After 15600 training step(s),loss on training batch is 0.0254986.The batch test accuracy = 1 , 1 ，1.
After 15700 training step(s),loss on training batch is 0.643928.The batch test accuracy = 1 , 1 ，1.
After 15800 training step(s),loss on training batch is 0.00265242.The batch test accuracy = 1 , 1 ，1.
After 15900 training step(s),loss on training batch is 0.0623317.The batch test accuracy = 1 , 1 ，1.
After 16000 training step(s),loss on training batch is 0.0970159.The batch test accuracy = 1 , 1 ，1.
After 16100 training step(s),loss on training batch is 0.512892.The batch test accuracy = 1 , 1 ，1.
After 16200 training step(s),loss on training batch is 0.028259.The batch test accuracy = 1 , 1 ，1.
After 16300 training step(s),loss on training batch is 0.115967.The batch test accuracy = 1 , 1 ，1.
After 16400 training step(s),loss on training batch is 0.00934216.The batch test accuracy = 1 , 1 ，1.
After 16500 training step(s),loss on training batch is 0.00524225.The batch test accuracy = 1 , 1 ，1.
After 16600 training step(s),loss on training batch is 0.00964493.The batch test accuracy = 1 , 1 ，1.
After 16700 training step(s),loss on training batch is 0.019591.The batch test accuracy = 1 , 1 ，1.
After 16800 training step(s),loss on training batch is 0.00160519.The batch test accuracy = 1 , 1 ，1.
After 16900 training step(s),loss on training batch is 0.000401628.The batch test accuracy = 1 , 1 ，1.
After 17000 training step(s),loss on training batch is 0.0130226.The batch test accuracy = 1 , 1 ，1.
After 17100 training step(s),loss on training batch is 1.55197.The batch test accuracy = 1 , 1 ，1.
After 17200 training step(s),loss on training batch is 0.0377348.The batch test accuracy = 1 , 1 ，1.
After 17300 training step(s),loss on training batch is 0.0171371.The batch test accuracy = 1 , 1 ，1.
After 17400 training step(s),loss on training batch is 0.00284458.The batch test accuracy = 1 , 1 ，1.
After 17500 training step(s),loss on training batch is 0.00169246.The batch test accuracy = 1 , 1 ，1.
After 17600 training step(s),loss on training batch is 0.00093862.The batch test accuracy = 1 , 1 ，1.
After 17700 training step(s),loss on training batch is 0.00125823.The batch test accuracy = 1 , 1 ，1.
After 17800 training step(s),loss on training batch is 0.00964364.The batch test accuracy = 1 , 1 ，1.
After 17900 training step(s),loss on training batch is 0.0023124.The batch test accuracy = 1 , 1 ，1.
After 18000 training step(s),loss on training batch is 0.0472137.The batch test accuracy = 1 , 1 ，1.
After 18100 training step(s),loss on training batch is 0.0271252.The batch test accuracy = 1 , 1 ，1.
After 18200 training step(s),loss on training batch is 0.0555564.The batch test accuracy = 1 , 1 ，1.
After 18300 training step(s),loss on training batch is 0.18879.The batch test accuracy = 1 , 1 ，1.
After 18400 training step(s),loss on training batch is 0.00323093.The batch test accuracy = 0.992188 , 1 ，1.
After 18500 training step(s),loss on training batch is 0.117685.The batch test accuracy = 1 , 1 ，1.
After 18600 training step(s),loss on training batch is 0.0189709.The batch test accuracy = 1 , 1 ，1.
After 18700 training step(s),loss on training batch is 0.111573.The batch test accuracy = 1 , 1 ，1.
After 18800 training step(s),loss on training batch is 0.00139856.The batch test accuracy = 0.992188 , 1 ，1.
After 18900 training step(s),loss on training batch is 0.0309244.The batch test accuracy = 1 , 1 ，1.
After 19000 training step(s),loss on training batch is 0.00425593.The batch test accuracy = 1 , 1 ，1.
After 19100 training step(s),loss on training batch is 0.187562.The batch test accuracy = 1 , 1 ，1.
After 19200 training step(s),loss on training batch is 0.0394335.The batch test accuracy = 1 , 1 ，1.
After 19300 training step(s),loss on training batch is 0.004569.The batch test accuracy = 1 , 1 ，1.
After 19400 training step(s),loss on training batch is 0.00697908.The batch test accuracy = 1 , 1 ，1.
After 19500 training step(s),loss on training batch is 0.00587189.The batch test accuracy = 1 , 1 ，1.
After 19600 training step(s),loss on training batch is 0.00264092.The batch test accuracy = 1 , 1 ，1.
After 19700 training step(s),loss on training batch is 0.0884062.The batch test accuracy = 1 , 1 ，1.
After 19800 training step(s),loss on training batch is 0.00806805.The batch test accuracy = 1 , 1 ，1.
After 19900 training step(s),loss on training batch is 0.101858.The batch test accuracy = 0.992188 , 1 ，1.
After 20000 training step(s),loss on training batch is 0.0423556.The batch test accuracy = 1 , 1 ，1.
After 20100 training step(s),loss on training batch is 0.0295168.The batch test accuracy = 1 , 1 ，1.
After 20200 training step(s),loss on training batch is 0.00448291.The batch test accuracy = 1 , 1 ，1.
After 20300 training step(s),loss on training batch is 0.0108747.The batch test accuracy = 1 , 1 ，1.
After 20400 training step(s),loss on training batch is 0.0107907.The batch test accuracy = 1 , 1 ，1.
After 20500 training step(s),loss on training batch is 1.01015.The batch test accuracy = 1 , 1 ，1.
After 20600 training step(s),loss on training batch is 0.0018781.The batch test accuracy = 1 , 1 ，1.
After 20700 training step(s),loss on training batch is 0.0142789.The batch test accuracy = 1 , 1 ，1.
After 20800 training step(s),loss on training batch is 0.0159835.The batch test accuracy = 1 , 1 ，1.
After 20900 training step(s),loss on training batch is 0.00843252.The batch test accuracy = 1 , 1 ，1.
After 21000 training step(s),loss on training batch is 0.00116903.The batch test accuracy = 1 , 1 ，1.
After 21100 training step(s),loss on training batch is 0.000323305.The batch test accuracy = 1 , 1 ，1.
After 21200 training step(s),loss on training batch is 0.0283681.The batch test accuracy = 1 , 1 ，1.
After 21300 training step(s),loss on training batch is 0.0266865.The batch test accuracy = 1 , 1 ，1.
After 21400 training step(s),loss on training batch is 0.104444.The batch test accuracy = 1 , 1 ，1.
After 21500 training step(s),loss on training batch is 0.000981516.The batch test accuracy = 1 , 1 ，1.
After 21600 training step(s),loss on training batch is 0.0262641.The batch test accuracy = 1 , 1 ，1.
After 21700 training step(s),loss on training batch is 0.000948484.The batch test accuracy = 1 , 1 ，1.
After 21800 training step(s),loss on training batch is 0.0522948.The batch test accuracy = 1 , 1 ，1.
After 21900 training step(s),loss on training batch is 0.0277127.The batch test accuracy = 1 , 1 ，1.
After 22000 training step(s),loss on training batch is 0.0258038.The batch test accuracy = 1 , 1 ，1.
After 22100 training step(s),loss on training batch is 0.0291036.The batch test accuracy = 1 , 1 ，1.
After 22200 training step(s),loss on training batch is 0.164859.The batch test accuracy = 1 , 1 ，1.
After 22300 training step(s),loss on training batch is 0.0149223.The batch test accuracy = 1 , 1 ，1.
After 22400 training step(s),loss on training batch is 0.0115659.The batch test accuracy = 1 , 1 ，1.
Interrupted on request...
Train finished...
